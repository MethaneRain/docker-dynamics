{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  - MTR 3420 Dynamics - Interactive Lab Notebook - \n",
    "##  - Data Notebook  - \n",
    "###  - Justin Richling - \n",
    "####  - 08/20/2018 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This lab will allow many learning opportunities: \n",
    "\n",
    "* Reading Data from NetCDF File\n",
    "* Working with Multidimensional Arrays\n",
    "* Creating Functions\n",
    "* Running Calculations\n",
    "* Saving New Data to New NetCDF File\n",
    "* Learning Python, common programming language terminology and good habits\n",
    "* Algorithms - Learning how to think rationally\n",
    "* Using Working Notebook - chance to use HTML and Tex formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center><font face=\"fantasy, serif\" color=#233513 style=\"font-size:35px\">-----------------------------//-----------------------------</font></center></h3>\n",
    "<h1> <center>Storm Intro </center></h1>\n",
    "<h3><center><font face=\"fantasy, serif\" color=#233513 style=\"font-size:35px\">-----------------------------//-----------------------------</font></center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snow Totals\n",
    "<img src='http://mediaassets.scrippsnationalnews.com/photo/2016/02/01/GroundhogDayBlizzard-SnowfallTotals_1454342782744_31151996_ver1.0_900_675.jpg' height=\"600\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflectivity\n",
    "<img src='http://www.bouldercast.com/wp-content/uploads/2016/02/18Z-20160201_hrrrCGPsf_prec_radar.gif' height=\"600\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Map\n",
    "\n",
    "<img src=\"http://www2.mmm.ucar.edu/imagearchive1/SatSfcComposite/20160202/sat_sfc_map_2016020207.gif\" height=\"600\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](1000and500mb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 500mb Vorticity\n",
    "<img src=\"http://www2.mmm.ucar.edu/imagearchive1/ETA500mbAnalysis/vorticity/20160202/eta500_vrt_2016020208.gif\" height=\"600\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>In Python we can import external libraries that we can download which will help us in numerous ways</h1>\n",
    "\n",
    "* One of the most useful aspects of Python is being able to import external libraries (once you have them downloaded) to help with such things like mathematical calcs, plotting, working with arrays and specific types of data files (NetCDF for example).<br>\n",
    "\n",
    "\n",
    "* We can also use them for grabbing things from the internet or the operating system of our computer like command line operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/username/Downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy is Python's math library and helps us with calculations. Trig functions, constants and \n",
    "# symbols are accessable.\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib is Pyhton's plotting library and pyplot is where all our plotting be be coming from\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This can allow us to Gaussian smooth the data if desired\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "# It wouldn't be a bad idea to save our calulations in a new .nc file so we don't have to run calculations\n",
    "# everytime we open our notebook.\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "from netCDF4 import Dataset as NetCDFFile\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import num2date, date2num\n",
    "\n",
    "# A very handy function to hide the cells from view so the students couldn't see my work but see the output\n",
    "import Cell_Hide_Toggle \n",
    "\n",
    "# Make sure we don't break anything trying to import our libraries\n",
    "print(\"imports are all good.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's time to pull some data from our NetCDF file!\n",
    "    \n",
    "* What we will be doing time and time again is assigning data, numbers, strings, etc to <i>variables</i>. This allows us to keep accessing the data once the data file is closed. Most importantly it will allow us to be free to probe the information stored in the variable over and over again in our <i>for-loops</i>.\n",
    "\n",
    "\n",
    "* Setting the file path as a variable <i>ds</i> for the data file. Find out where this file lives on your computer. We can use the command line or through finder windows on the desktop.\n",
    "\n",
    "\n",
    "* Then calling NetCDFFile() will read all the data from the NetCDF file and we can print it out to examine what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = NetCDFFile('/home/username/Downloads/hgt.2016.nc')\n",
    "ds = NetCDFFile('/Users/chowdahead/Downloads/hgt.2016.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The newly saved data set can be probed by key words inherent to the file. We can find what the different variables are in the data set by calling the $keys()$ function of $ds$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ds.variables.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To explore the data available in any of the variables we just call ds by the variable name. Remember that the quotes are strings, so we're searching the whole data set by a specific name and it will return all the values and metadata if it is an appropriate variable within the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the 'level' metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.variables['level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the pressure levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.variables['level'].units)\n",
    "list(ds.variables['level'][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the 'lon' metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.variables['lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the 'time' metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.variables[\"time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember the concpet of finding slices of data? Below we will try and access the 140th entry of the lon variable. Note: this is not the longitude itself, it will print out what longitude 140 is in a set of 144 lons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.variables['lon'][140])\n",
    "\n",
    "# actual_range:   [   0.   357.5]  \n",
    "# means (0,2.5,...,355,357.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are going to grab all the values for each variable and assign them to a new arrays: Lat, Lon, Time, and Level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the data from the file and put the data into aarrays\n",
    "Lats = ds.variables['lat'][:] # [:] is all values, remeber slices?\n",
    "Lons = ds.variables['lon'][:]\n",
    "Times = ds.variables['time'][:]\n",
    "Levels = ds.variables['level'][:]\n",
    "\n",
    "print(\"Data type of our new arrays: \",type(Lons))\n",
    "print(\"Shape of Lat array: \",Lats.shape[0])\n",
    "print(\"Shape of Lon array: \",Lons.shape[0])\n",
    "print(\"Shape of Time array: \",Times.shape[0])\n",
    "print(\"Shape of Level array: \",Levels.shape[0])\n",
    "print(\"Number of dimensions for Level array: \"+str(len(Levels.shape))+\", meaning 1 dimension of length 17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets find the index number in Level array for say 500mb\n",
    "mylevel = input(\"Which mb level: \")\n",
    "level_index = np.where(Levels == float(mylevel))[0][0]\n",
    "print(\"Pressure level index of input: \",level_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to find which index number Denver's lat and lon are knowing that Denver is approximately 40 N and -105 W or 255 E.\n",
    "\n",
    "\n",
    "### We can use the indexing to find Denver's lat and lon in the same way we did before with the pressure level: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylat = input(\"Which latitude? (-90 to 90) \")\n",
    "DenLat_index = np.where(Lats == float(mylat))[0][0]\n",
    "print(\"Index number for Denver lat: \",DenLat_index,\"\\n\") # The \\n just means print new line\n",
    "\n",
    "mylon = input(\"Which latitude? (0 to 357.5) \") # Think about what is the range of the lons in this data set?\n",
    "if float(mylon) < 0.:\n",
    "    mylon = 360.+float(mylon)\n",
    "DenLon_index = np.where(Lons == float(mylon))[0][0]\n",
    "print(\"Index number for Denver lon: \",DenLon_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So Lat[20] = 40 deg north = Denver's Lat\n",
    "    \n",
    "### And Lon[102] = 255 deg east or -105 deg west = Denver's Lon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we want to know the index number for Feb. 2nd, 12:00Z is in the $Time$ array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "january=31*4 #31 days in January, multiplied by 4 for 00, 06, 12, and 18Z each day\n",
    "groundhog=4+3 #4 time steps on the 1st plus 0 z on the 2nd, 6 z on the 2nd, 12 z on the second \n",
    "time_index=january+groundhog-1 # Reason for the minus one??\n",
    "print(\"Day of year index number:\",time_index,\"\\n\")\n",
    "\n",
    "# time_index is the variable for the index number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert time variable into a date and check to see if it's the time we wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in times.\n",
    "dates = [datetime(2016,1,1)+n*timedelta(hours=6) for n in range(Times.shape[0])]\n",
    "\n",
    "mydate = dates[time_index]\n",
    "mydate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that you've figured out the index values for time, level, and Denvers' lat and lon, lets hard code it so the next time you don't have to go through the user input prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these if you just want to assign to variables and move on quickly...\n",
    "\n",
    "DenLat_index = 20\n",
    "DenLon_index = 102\n",
    "time_index = 130\n",
    "level_index = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can populate a 4d array of time, level, lat, and lon. Each entry in the new 4d array will have a height value in meters:\n",
    "\n",
    "* Give this a minute as it is doing some heavy lifting populating all the indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# hgt(time, level, lat, lon)\n",
    "Heights = ds.variables['hgt'][:,:,:,:]\n",
    "\n",
    "print(\"Shape of the full height array:\",Heights.shape)\n",
    "\n",
    "# If we call height[0,0,0,0] we would expect a number; a 32-decimal float\n",
    "print(\"Data type of height[0,0,0,0]:\",type(Heights[0,0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can take a subset of the lat/lons to only get CONUS\n",
    "\n",
    "This may help with time for the calculations and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the CONUS we need the index range for lats (12:32) and lons (88:122)\n",
    "CONUS_height = Heights[:,:,12:32,88:122]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One cool feature of accessing metadata is getting metadata to save as variables too. Here we are pulling the description of the name of the variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height array stored all the actual values of ds[\"hgt\"], but not the metadata like descriptions (.var_descr)\n",
    "\n",
    "hgt_descr = str(ds.variables['hgt'].var_desc)\n",
    "print(\"What 'hgt' variable is:\",hgt_descr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since we've loaded all our data we can close the file so it's not running in the background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK, let's pull some of the geopotential heights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONUS_height\n",
    "hgt129_500mb=CONUS_height[time_index-1,5,:,:]\n",
    "\n",
    "hgt130_Surf=CONUS_height[time_index,0,:,:]\n",
    "hgt130_500mb=CONUS_height[time_index,5,:,:]\n",
    "\n",
    "hgt131_500mb=CONUS_height[time_index+1,5,:,:]\n",
    "\n",
    "# Set the countour levels for both heights\n",
    "hgt129_500mb_levels = np.arange(hgt129_500mb.min(),hgt129_500mb.max()+53,60)\n",
    "\n",
    "hgt130_Surf_levels = np.arange(-20,400,40) \n",
    "hgt130_500mb_levels = np.arange(hgt130_500mb.min(),hgt130_500mb.max()+53,60) \n",
    "\n",
    "hgt131_500mb_levels = np.arange(hgt131_500mb.min(),hgt131_500mb.max()+53,60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want to smooth the data with a Gaussian filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothed Data\n",
    "# Gaussian Filter to smooth the data and make it a little neater \n",
    "#hgt129_500mb_smooth = ndimage.gaussian_filter(hgt129_500mb, sigma=1, order=0)\n",
    "#hgt129_Surf_smooth = ndimage.gaussian_filter(hgt129_Surf, sigma=1, order=0)\n",
    "\n",
    "#hgt130_500mb_smooth = ndimage.gaussian_filter(hgt130_500mb, sigma=1, order=0)\n",
    "#hgt130_Surf_smooth = ndimage.gaussian_filter(hgt130_Surf, sigma=1, order=0)\n",
    "\n",
    "#hgt131_500mb_smooth = ndimage.gaussian_filter(hgt131_500mb, sigma=1, order=0)\n",
    "#hgt131_Surf_smooth = ndimage.gaussian_filter(hgt131_Surf, sigma=1, order=0)\n",
    "\n",
    "\n",
    "# Smoothed Levels\n",
    "#hgt129_Surf_levels_smooth = np.arange(0,400,40) \n",
    "#hgt129_500mb_levels_smooth = np.arange(hgt129_500mb_smooth.min(),hgt129_500mb_smooth.max(),60)\n",
    "\n",
    "#hgt130_Surf_levels_smooth = np.arange(0,400,40) \n",
    "#hgt130_500mb_levels_smooth = np.arange(hgt130_500mb_smooth.min(),hgt130_500mb_smooth.max(),60)\n",
    "\n",
    "#hgt131_Surf_levels_smooth = np.arange(0,400,40) \n",
    "#hgt131_500mb_levels_smooth = np.arange(hgt131_500mb_smooth.min(),hgt131_500mb_smooth.max(),60) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's also fill our calculation .nc file with lats, lons, hights, and times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's make the new .nc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make our own NetCDF file so we can keep track of our progress:\n",
    "new_ds = Dataset('/Users/chowdahead/Desktop/Groundhogs_Day_Storm_Calcs.nc','w')\n",
    "new_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can create the variables based on a desired dimension size and fill them with our data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#datafile2 = NetCDFFile('/home/username/Desktop/Groundhogs_Day_Storm_Calcs.nc','a')\n",
    "new_ds = NetCDFFile('/Users/chowdahead/Desktop/Groundhogs_Day_Storm_Calcs.nc','a')\n",
    "\n",
    "level_size = new_ds.createDimension('level_size', len(Level))\n",
    "lat_size = new_ds.createDimension('lat_size', len(Lat))\n",
    "lon_size = new_ds.createDimension('lon_size', len(Lon))\n",
    "date_size = new_ds.createDimension('date_size', len(Time))\n",
    "\n",
    "levels = new_ds.createVariable('level', np.int32, ('level_size',))\n",
    "latitudes = new_ds.createVariable('latitude', np.float32,('lat_size',))\n",
    "longitudes = new_ds.createVariable('longitude', np.float32,('lon_size',))\n",
    "datez = new_ds.createVariable('dates', np.float32, ('date_size',))\n",
    "\n",
    "# Create the 4-d array for geopotential heights\n",
    "hgts = new_ds.createVariable('hgt', np.float32,('date_size','level_size','lat_size','lon_size'))\n",
    "\n",
    "# We take the variables we just created and assign the values of our data arrays\n",
    "levels[:] = Level\n",
    "latitudes[:] = Lat\n",
    "longitudes[:] = Lon\n",
    "datez[:] = Time\n",
    "hgts[:] = height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(new_ds.variables.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions!\n",
    "\n",
    "### Now time to define a fucntion so we can call it many times and get all the values we need like a programmable calculator. \n",
    "\n",
    "### PGF will be the name of the function and and the arguments in the parenthesis will be the variables it needs to run the calculation.\n",
    "\n",
    "### $PGF = -(\\frac{\\partial \\Phi_{i}}{\\partial x} \\hat{i} + \\frac{\\partial \\Phi_{j}}{\\partial y} \\hat{j} )= -(\\frac{\\Delta\\Phi_{lon}}{\\Delta x} \\hat{i} + \\frac{\\Delta\\Phi_{lat}}{\\Delta y} \\hat{j} )$\n",
    "\n",
    "\n",
    "### $PGF = -(\\frac{\\Phi_{east} - \\Phi_{west}}{2dx} \\hat{i} + \\frac{\\Phi_{north} - \\Phi_{south}}{2dy} \\hat{j} ) = -g(\\frac{Z_{east} - Z_{west}}{2dx} \\hat{i} + \\frac{Z_{north} - Z_{south}}{2dy} \\hat{j} )$\n",
    "\n",
    "### $PGF_{x} = -g(\\frac{Z_{east} - Z_{west}}{2dx} \\hat{i})$ \n",
    "\n",
    "### $PGF_{y} = -g(\\frac{Z_{north} - Z_{south}}{2dy} \\hat{j})$\n",
    "\n",
    "### $\\left\\lvert{PGF}\\right\\rvert = \\sqrt{PGF_{x}^{2}+PGF_{y}^{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGF(height_east,height_west,height_north,height_south,dx,dy):\n",
    "    \n",
    "    pgfx = -9.8*((height_east-height_west)/(dx*2))\n",
    "    pgfy = -9.8*((height_north-height_south)/(dy*2))\n",
    "    pgf = np.sqrt((pgfx**2)+(pgfy**2))\n",
    "    \n",
    "    return float(pgfx), float(pgfy), float(pgf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we know the beam angle of the instrument and the lat and lon values, the dx and dy can be calcluated knowing that 2.5 deg of latitude is 278km and 2.5 deg of longitude is 213km:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 213000\n",
    "dy = 278000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can calculate the geopotential heights at and around Denver. Taking these heights will allow us to calculate the PGF at Denver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_Denver = Heights[time_index,level_index,DenLat_index,DenLon_index]\n",
    "print(\"Denver's height:\",height_Denver,\"m\")\n",
    "\n",
    "###########################################################################\n",
    "# The reason why the northern height is Denlat-1 instead of +1 is because \n",
    "# how the lat data is plotted in Python\n",
    "height_north = Heights[time_index,level_index,DenLat_index-1,DenLon_index]\n",
    "print(\"Height north:\",height_north,\"m\")\n",
    "\n",
    "height_south = Heights[time_index,level_index,DenLat_index+1,DenLon_index]\n",
    "print(\"Height south:\",height_south,\"m\")\n",
    "###########################################################################\n",
    "\n",
    "height_east = Heights[time_index,level_index,DenLat_index,DenLon_index+1]\n",
    "print(\"Height east:\",height_east,\"m\")\n",
    "\n",
    "height_west = Heights[time_index,level_index,DenLat_index,DenLon_index-1]\n",
    "print(\"Height west:\",height_west,\"m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_Denver = Heights[time_index,level_index,DenLat_index,DenLon_index]\n",
    "\n",
    "height_north = Heights[, , , ]\n",
    "\n",
    "height_south = Heights[, , , ]\n",
    "\n",
    "height_east = Heights[, , , ]\n",
    "\n",
    "height_west = Heights[, , , ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The variables in the PGF function returns 3 values, so we can set 3 variables when calling the PGF function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgfx,pgfy,pgf = PGF(height_east,height_west,height_north,height_south,dx,dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can print it out a little neater in scientific notation:\n",
    "\n",
    "* (%.3e means 3 decimal places in 'e' or scientific notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PGFx at Denver:','%.3e' % pgfx)\n",
    "print('PGFy at Denver:','%.3e' % pgfy)\n",
    "print('PGF resultant:','%.3e' % pgf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Day 1 Data, I'm Proud of You!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also define another function for the Coriolis factor CorFac: \n",
    "\n",
    "## $f = 2\\Omega sin{\\phi} \\hspace{10 mm} \\Omega=7.292e^{-5}s^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to pass the latitude from the Lat array to get the value!\n",
    "\n",
    "def CorParam(lat_index):\n",
    "    f = 2*7.292E-5*np.sin(Lats[lat_index]*np.pi/180)\n",
    "    return float(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = CorParam(DenLat_index)\n",
    "print('Coriolis factor over Denver: ',f)\n",
    "print('Coriolis factor over Denver: %.3e' % f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would we want to scale this up to collect the Coriolis factor for all latitudes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initate an empty 1d array to populate with Coriolis factors for each lat\n",
    "#COR = xr.DataArray(np.zeros((73)),dims=['x'],coords={'x': Lat})\n",
    "COR = np.zeros((73))\n",
    "\n",
    "for i in range(0,73):\n",
    "    COR[i]=CorParam(i)\n",
    "        \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also add the Coriolis Factor to our calcuations .nc file too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = NetCDFFile('/Users/chowdahead/Desktop/Groundhogs_Day_Storm_Calcs.nc','a')\n",
    "\n",
    "corfac = new_ds.createDimension('Cor_factor', len(Lat))\n",
    "\n",
    "Cor_factor = new_ds.createVariable('corfac', np.int32, ('lat',))\n",
    "Cor_factor[:] = COR\n",
    "\n",
    "new_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(new_ds.variables.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Day 2 Data, No sweat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With the geopotential height differences and the Coriolis factor, the geostrophic winds can be calculated.\n",
    "\n",
    "## $\\vec{V_{g}} = -\\frac{1}{f}(\\frac{\\partial \\Phi_{j}}{\\partial y} \\hat{i} - \\frac{\\partial \\Phi_{i}}{\\partial x} \\hat{j} )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's break the total horizontal geostrophic wind vector into it's zonal and meridonal components:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\vec{u_{g}} = -\\frac{1}{f}(\\frac{\\partial \\Phi_{j}}{\\partial y})\\hspace{.1cm}\\hat{i}= -\\frac{g}{f}(\\frac{\\partial Z_{j}}{\\partial y})\\hspace{.1cm}\\hat{i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uGeoWind(level_index,time_index,lat_index,lon_index,dy):\n",
    "    ug = (-9.8/CorParam(lat_index))*\\\n",
    "          ((Heights[time_index,level_index,lat_index-1,lon_index]-\n",
    "            Heights[time_index,level_index,lat_index+1,lon_index])/(dy*2))   \n",
    "\n",
    "    return ug\n",
    "\n",
    "Cell_Hide_Toggle.hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vGeoWind(level_index,time_index,lat_index,lon_index,dy):\n",
    "    \n",
    "    vg = (9.8/CorParam())*\\\n",
    "          ((Heights[, , , ]-\n",
    "            Heights[, , , ])/(dx*2))   \n",
    "\n",
    "    return vg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\vec{v_{g}} = \\frac{1}{f}(\\frac{\\partial \\Phi_{i}}{\\partial x})\\hspace{.1cm}\\hat{j} = \\frac{g}{f}(\\frac{\\partial Z_{i}}{\\partial x})\\hspace{.1cm}\\hat{j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vGeoWind(level_index,time_index,lat_index,lon_index,dx):\n",
    "    vg = (9.8/CorParam(lat_index))*\\\n",
    "          ((Heights[time_index,level_index,lat_index,lon_index+1]-\n",
    "            Heights[time_index,level_index,lat_index,lon_index-1])/(dx*2))   \n",
    "    \n",
    "    return vg\n",
    "Cell_Hide_Toggle.hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\left\\lvert{V_{g}}\\right\\rvert= \\sqrt{u_{g}^{2}+v_{g}^{2}}$\n",
    "\n",
    "### We'll define another function called GeoWind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeoWind(level_index,time_index,lat_index,lon_index,dx,dy):\n",
    "\n",
    "    ug = uGeoWind(level_index,time_index,lat_index,lon_index,dy)\n",
    "    vg = vGeoWind(level_index,time_index,lat_index,lon_index,dx)\n",
    "    \n",
    "    return np.sqrt((ug**2)+(vg**2))\n",
    "\n",
    "Cell_Hide_Toggle.hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = uGeoWind(level_index,time_index,DenLat_index,DenLon_index,dy)\n",
    "print('zonal compnent: %.3f' % u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = vGeoWind(level_index,time_index,DenLat_index,DenLon_index,dx)\n",
    "print('meridional compnent: %.3f' % v)\n",
    "\n",
    "U = GeoWind(level_index,time_index,DenLat_index,DenLon_index,dx,dy)\n",
    "print('total geostrophic wind: %.3f' % U)\n",
    "\n",
    "Cell_Hide_Toggle.hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can find the rose angle of the Geostrophic wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = np.arccos(u/U)*(180/np.pi)\n",
    "# We can round the decimal to two places:\n",
    "angle = np.around(angle,2)\n",
    "print(angle,\"degrees from x-axis\")\n",
    "\n",
    "Cell_Hide_Toggle.hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new arrays for our calculations\n",
    "    \n",
    "## Don't focus on the how so much as to what you are getting in the end. We are making a 2d array named WindsFull_130_500mb with coordiantes of lat and lon only. This array is focused on time 130 and level 500mb.\n",
    "\n",
    "## In the nested for-loop we will need to loop over all the lats and lons seperately so we will have a wind value for every lat/lon pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Winds_130_500mb = np.zeros((73, 144))\n",
    "uWinds_130_500mb = np.zeros((73, 144))\n",
    "vWinds_130_500mb = np.zeros((73, 144))\n",
    "print(Winds_130_500mb.shape)\n",
    "\n",
    "# We need to go from the second entry to the second to last entry, why?\n",
    "for i in range(1,72):\n",
    "    for j in range(1,143):\n",
    "            try:\n",
    "                Winds_130_500mb[i,j]=GeoWind(level_index,time_index,i,j,dx,dy) # What arguments does GeoWind take?\n",
    "                uWinds_130_500mb[i,j]=uGeoWind(level_index,time_index,i,j,dy)\n",
    "                vWinds_130_500mb[i,j]=vGeoWind(level_index,time_index,i,j,dx)\n",
    "            except ZeroDivisionError:\n",
    "                normalized_score = 0\n",
    "                \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Winds min value:\",Winds_130_500mb.min())\n",
    "print('Winds max value: %.3f' % Winds_130_500mb.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up arrays for the days before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Winds_129_500mb = np.zeros((73, 144))\n",
    "uWinds_129_500mb = np.zeros((73, 144))\n",
    "vWinds_129_500mb = np.zeros((73, 144))\n",
    "\n",
    "Winds_131_500mb = np.zeros((73, 144))\n",
    "uWinds_131_500mb = np.zeros((73, 144))\n",
    "vWinds_131_500mb = np.zeros((73, 144))\n",
    "print(Winds_131_500mb.shape)\n",
    "\n",
    "for i in range(1,72):\n",
    "    for j in range(1,143):\n",
    "        try:\n",
    "            Winds_129_500mb [i,j]=GeoWind(level_index,time_index,i,j,dx,dy)\n",
    "        except ZeroDivisionError:\n",
    "                normalized_score = Winds_129_500mb[i-1,j-1] \n",
    "                \n",
    "for i in range(1,72):\n",
    "    for j in range(1,143):\n",
    "        try:\n",
    "            Winds_131_500mb [i,j]=GeoWind(level_index,time_index,i,j,dx,dy)\n",
    "        except ZeroDivisionError:\n",
    "                normalized_score = Winds_131_500mb[i-1,j-1] \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's update our calculations .nc file with the winds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = NetCDFFile('/Users/chowdahead/Desktop/Groundhogs_Day_Storm_Calcs.nc','a')\n",
    "\n",
    "# 2-d arrays at days 129, 130, and 131 and 500mb only\n",
    "uwinds_130_500 = new_ds.createVariable('uwinds_130_500', np.float32,('lat_size','lon_size',))\n",
    "vwinds_130_500 = new_ds.createVariable('vwinds_130_500', np.float32,('lat_size','lon_size',))\n",
    "\n",
    "winds_129_500 = new_ds.createVariable('winds_129_500', np.float32,('lat_size','lon_size',))\n",
    "winds_130_500 = new_ds.createVariable('winds_130_500', np.float32,('lat_size','lon_size',))\n",
    "winds_131_500 = new_ds.createVariable('winds_131_500', np.float32,('lat_size','lon_size',))\n",
    "\n",
    "uwinds_130_500[:] = uWinds_130_500mb\n",
    "vwinds_130_500[:] = vWinds_130_500mb\n",
    "\n",
    "winds_129_500[:] = Winds_129_500mb\n",
    "winds_130_500[:] = Winds_130_500mb\n",
    "winds_131_500[:] = Winds_131_500mb\n",
    "\n",
    "new_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(new_ds.variables.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In case we wanted to fill the geostrophic winds at all levels for this day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Winds_130 = np.zeros((73, 144, 17))\n",
    "print(Winds_130.shape)\n",
    "\n",
    "for i in range(1,72):\n",
    "    for j in range(1,143):\n",
    "        for k in range(0,17):\n",
    "            try:\n",
    "                Winds_130[i,j,k]=GeoWind(k,time_index,i,j,dx,dy)\n",
    "            except ZeroDivisionError:\n",
    "                normalized_score = Winds_130[i-1,j-1,k] \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Day 3 Data, Hanging In there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have the geostrophic winds, we can take a look at vorticity using the change in winds over distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\zeta = (\\frac{\\partial v_{geo}}{\\partial x} - \\frac{\\partial u_{geo}}{\\partial y} )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can define a vorticity function, Vort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vort(level_index,time_index,lat_index,lon_index,dx,dy):    \n",
    "    vort = ((vGeoWind(level_index,time_index,lat_index,lon_index+1,dx)-vGeoWind(level_index,time_index,lat_index,lon_index-1,dx))/(2*dx))-\\\n",
    "            ((uGeoWind(level_index,time_index,lat_index-1,lon_index,dy)-uGeoWind(level_index,time_index,lat_index+1,lon_index,dy))/(2*dy))\n",
    "    return vort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the vorticity over Denver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vort(level_index,time_index,DenLat_index,DenLon_index,dx,dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will do the same thing for the vorticity array as we did for the geostrophic winds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Vort_130_500mb = np.zeros((73, 144))\n",
    "print(Vort_130_500mb.shape)\n",
    "\n",
    "# We have to change the range for our for-loops, before we could use \n",
    "for i in range(2,71):\n",
    "    for j in range(2,141):\n",
    "        try:\n",
    "            Vort_130_500mb[i,j]=Vort(level_index,time_index,i,j,dx,dy)\n",
    "        except ZeroDivisionError:\n",
    "            normalized_score = 0\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum vorticity value in array: %.3e\" % Vort_130_500mb.min())\n",
    "print(\"Minimum vorticity value in array: %.3e\" % Vort_130_500mb.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up arrays for the times before and after\n",
    "* Again, give this some time to calculate and populate all the indicies for all the times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Vort_129_500mb = np.zeros((73, 144))\n",
    "Vort_131_500mb = np.zeros((73, 144))\n",
    "print(Vort_129_500mb.shape)\n",
    "\n",
    "for i in range(1,71):\n",
    "    for j in range(1,142):\n",
    "        try:\n",
    "            Vort_129_500mb[i,j]=Vort(level_index,time_index-1,i,j,dx,dy)\n",
    "            Vort_131_500mb[i,j]=Vort(level_index,time_index+1,i,j,dx,dy)\n",
    "        except ZeroDivisionError:\n",
    "            normalized_score = Vort_129_500mb[i-1,j-1] \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One last variable to add to our calculations .nc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = NetCDFFile('/Users/chowdahead/Desktop/Groundhogs_Day_Storm_Calcs.nc','a')\n",
    "\n",
    "# 2-d arrays at days 129, 130, and 131 and 500mb only\n",
    "vorts_129_500 = new_ds.createVariable('vorticity_129_500', np.float32,('lat_size','lon_size',))\n",
    "vorts_130_500 = new_ds.createVariable('vorticity_130_500', np.float32,('lat_size','lon_size',))\n",
    "vorts_131_500 = new_ds.createVariable('vorticity_131_500', np.float32,('lat_size','lon_size',))\n",
    "\n",
    "vorts_129_500[:] = Vort_129_500mb\n",
    "vorts_130_500[:] = Vort_130_500mb\n",
    "vorts_131_500[:] = Vort_131_500mb\n",
    "\n",
    "new_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(new_ds.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#('Winds max value: %.3e' % Vort_130_500mb.max())[-4:]\n",
    "('Winds max value: %.3e' % Vort_130_500mb.max())[-4:]\n",
    "#str(label '%.3e' % Vort_130_500mb.max()[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# -------------------------------------------//------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Day 4 Data, All Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
